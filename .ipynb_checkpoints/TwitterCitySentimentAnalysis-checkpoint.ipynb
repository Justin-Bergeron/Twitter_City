{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Youll have to install plot.ly for the map:    pip install plotly\n",
    "# 2.Add your Twitter keys\n",
    "# 3.Download the JSON file and put it in the same directory as this notebook https://gist.github.com/Miserlou/c5cd8364bf9b2420bb29   shoutout to this human for making the cities json file\n",
    "# 4.Make your output directory for the CSV\n",
    "# 5.Change jsonlen to the number of cities that you want to do, full list is 1000 test it with five first\n",
    "# 6.Change search_term to your search term \n",
    "# 7. Run the code. should take about 6 hours. Nothing will show up in the CSV file till it's done. just let it do its thing\n",
    "# 7. In next cell change the csv file to your output file for pandas\n",
    "# 8. In the plotly cell just change the title of the map. there should be a new window that opens with the map. \n",
    "# 9. In the top righthand corner of the windoe there is a button to download it as a PNG. \n",
    "# 10. Profit.\n",
    "\n",
    "\n",
    "import tweepy\n",
    "import json\n",
    "import csv\n",
    "import time\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "# Twitter API Keys\n",
    "consumer_key =\n",
    "consumer_secret =\n",
    "access_token = \n",
    "access_token_secret = \n",
    "\n",
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "# Open/create a file to append data to\n",
    "csvFile = open('PUT YOUR OUTPUT FILE HERE', 'w', encoding='utf-8')  #make 'a' to addend   put your output file here\n",
    "\n",
    "cities = json.load(open('YOUR DIRECTORY/cities.json'))  #Load the cities.json file here\n",
    "citylist = []\n",
    "latlong = []\n",
    "i = 0\n",
    "distance = '20mi'\n",
    "jsonlen = 10              #change this number to count of cities in the full list are for the full list\n",
    "\n",
    "while i < jsonlen:       \n",
    "    city = cities[i]['city']\n",
    "    citylist.append(city)\n",
    "    \n",
    "    lat = cities[i]['latitude']\n",
    "    long = cities[i]['longitude']\n",
    "    state = cities[i]['state']\n",
    "    geocode = (str(lat) + \",\" + str(long) + \",\" + str(distance))  \n",
    "    latlong.append(geocode)\n",
    "    i += 1\n",
    "    \n",
    "city_dict = dict(zip(citylist, latlong))  \n",
    "csvWriter = csv.writer(csvFile)\n",
    "csvWriter.writerow(['location', 'lat', 'long', 'tweet created at time', 'tweet text', 'tweet sentiment','tweet.user.geo_enabled'])\n",
    "\n",
    "c = 0\n",
    "search_term = ['RealDonaldTrump']       #put your search term here\n",
    "for key, value in city_dict.items():\n",
    "    testlat = value\n",
    "    t = 0\n",
    "    c+=1\n",
    "    print(f'{key} is {c} out of {jsonlen} cities')\n",
    "    for tweet in tweepy.Cursor(api.search,\n",
    "                               q = search_term,\n",
    "                               geocode=str(testlat),\n",
    "                               #count=100,\n",
    "                               lang = \"en\").items(100):\n",
    "        \n",
    "        if not tweet.retweeted and 'RT @' not in tweet.text:\n",
    "        # Write a row to the CSV file. I use encode UTF-8\n",
    "            csvWriter.writerow([key, testlat[0:10], testlat[11:22], tweet.created_at, tweet.text.encode('utf-8'), analyzer.polarity_scores(tweet.text)[\"compound\"], tweet.user.geo_enabled]) #testlat is split into lat and long\n",
    "            t += 1\n",
    "    print(str(t) + ' results')     \n",
    "    csvWriter.writerow        \n",
    "csvFile.close()\n",
    "\n",
    "print(api.rate_limit_status()['resources']['search']['/search/tweets'])  \n",
    "reset_time = api.rate_limit_status()['resources']['search']['/search/tweets']['reset']\n",
    "print('reset time: ' + time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(reset_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.plotly\n",
    "df = pd.read_csv('PUT YOUR OUTPUT CSV FILE HERE.csv')     #Just put your output file here the rest should run\n",
    "#print(df.head())\n",
    "df.reset_index()\n",
    "\n",
    "avgsent = df.groupby(['location'], as_index=True).agg(                             #get the mean sentiment for each city\n",
    "                      {'tweet sentiment':['mean']})\n",
    "avgcount = df.groupby(['location'], as_index=True).agg(                          #get a count of how many tweets there are for circle size\n",
    "                      {'tweet sentiment':['count']})\n",
    "\n",
    "lat = df.groupby(['location'], as_index=True)['location', 'lat'].head(1)         # get the lat\n",
    "lat1 = lat.set_index(['location'])\n",
    "\n",
    "long = df.groupby(['location'], as_index=True)['location', 'long'].head(1)     #same for long\n",
    "long1 = long.set_index(['location'])\n",
    "\n",
    "formap = pd.concat([avgsent, avgcount, lat1, long1], axis=1)\n",
    "latlong = pd.concat([lat1, long1],axis=1,)\n",
    "\n",
    "formap                                  #this is the cleaned df for the map                     \n",
    "formap = formap.rename( columns={\"(tweet sentiment, mean)\": \"avg sentiment\", \"(tweet sentiment, count)\": \"count\"})\n",
    "formap = formap.reset_index()\n",
    "formap.columns = ['city', 'mean sentiment', 'count', 'lat', 'long']\n",
    "formap['mean sentiment'] = formap['mean sentiment'].apply(lambda x: x*100) #make the mean sentiment go from -100 to 100\n",
    "formap.shape\n",
    "formap.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This prints everything to the map just change the title\n",
    "\n",
    "formap['text'] = formap['city'] + '<br>Mean Sentiment: ' + (formap['mean sentiment']).astype(str) + '<br>Tweet Count: ' + (formap['count']).astype(str)\n",
    "limits = [(0,10000)]\n",
    "cities = []\n",
    "\n",
    "\n",
    "for i in range(len(limits)):\n",
    "    \n",
    "    lim = limits[i]\n",
    "    formap_sub = formap[lim[0]:lim[1]]  \n",
    "    city = dict(\n",
    "        type = 'scattergeo',\n",
    "        locationmode = 'USA-states',\n",
    "        lon = formap_sub['long'],         \n",
    "        lat = formap_sub['lat'],\n",
    "        text=formap_sub['text'],\n",
    "        mode='markers',\n",
    "        marker = dict(\n",
    "            size = formap_sub['count'] * 2,\n",
    "            opacity = .7,\n",
    "            color = formap_sub['mean sentiment'],\n",
    "            colorscale='Blackbody',\n",
    "            showscale=True, \n",
    "            reversescale = False,\n",
    "            colorbar= dict(title = 'Sentiment Score <br>(100 = Positive) <br>(-100 = Negative)', titleseide = 'top'),\n",
    "            line = dict(width=0.5, color='rgb(40,40,40)'),\n",
    "            sizemode = 'area'\n",
    "        ),\n",
    "    )       \n",
    "    cities.append(city)\n",
    "\n",
    "layout = dict(\n",
    "        title = 'Facebook Sentiment',             #change the title here. \n",
    "        showlegend = False,\n",
    "        geo = dict(\n",
    "            scope='usa',\n",
    "            projection=dict( type='albers usa' ),\n",
    "            showland = True,\n",
    "            landcolor = 'rgb(217, 217, 217)',\n",
    "            subunitwidth=1,\n",
    "            countrywidth=1,\n",
    "            subunitcolor=\"rgb(255, 255, 255)\",\n",
    "            countrycolor=\"rgb(255, 255, 255)\"\n",
    "            \n",
    "        ),\n",
    "    )\n",
    "\n",
    "fig = dict( data=cities, layout=layout )\n",
    "plotly.offline.plot( fig, validate=False, filename='d3-bubble-map-populations.html' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
